{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**選擇兩本內建文本來做停用詞（stopwords）移除，並觀察它們在語料上的差異。**\n",
        "\n",
        "How stopwords (often function words) can be filtered out to better focus on the core (lexical) words that carry meaning."
      ],
      "metadata": {
        "id": "whFcPBhJ16mN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Install/Import the Required Packages and Resources\n",
        "\n"
      ],
      "metadata": {
        "id": "kv1Yg8hV2Q8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install/Import the Required Packages and Resources\n",
        "\n",
        "\n",
        "# If you have not installed NLTK yet, do so via pip:\n",
        "# pip install nltk\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import gutenberg, stopwords\n",
        "import string\n",
        "\n",
        "# Download the Gutenberg corpus and English stopwords\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('stopwords')\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "IXJchr8w2KWN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "270367c3-0eeb-434b-89e8-f23ab5f071a7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Choose Two Different Types of Books\n"
      ],
      "metadata": {
        "id": "2l1ru0xk2Xx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List all files in the Gutenberg corpus\n",
        "print(gutenberg.fileids())\n",
        "\n",
        "# Choose two file IDs\n",
        "book1_id = 'austen-emma.txt'   # A novel\n",
        "book2_id = 'bible-kjv.txt'     # The Bible\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "4oCS3VBH2XQd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16182497-d816-436d-dcc0-d15e2ee4ff46"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Read the Text and Perform Preprocessing\n"
      ],
      "metadata": {
        "id": "7i069WKw2dxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_words_book1 = gutenberg.words(book1_id)\n",
        "raw_words_book2 = gutenberg.words(book2_id)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "GL0AcWJP2dPl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2 Remove Stopwords and Punctuation\n",
        "\n",
        "1. Convert words to lowercase.\n",
        "\n",
        "2. Remove punctuation.\n",
        "\n",
        "3. Remove stopwords.\n"
      ],
      "metadata": {
        "id": "woHduCeH2g9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "punctuations = set(string.punctuation)\n",
        "\n",
        "def preprocess_and_remove_stopwords(words):\n",
        "    # Keep only alphabetic words and convert to lowercase\n",
        "    words = [w.lower() for w in words if w.isalpha()]\n",
        "    # Remove stopwords\n",
        "    words = [w for w in words if w not in stop_words]\n",
        "    return words\n",
        "\n",
        "book1_clean = preprocess_and_remove_stopwords(raw_words_book1)\n",
        "book2_clean = preprocess_and_remove_stopwords(raw_words_book2)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "AfxkQ99t2gIl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Simple Analyses\n"
      ],
      "metadata": {
        "id": "_B3Cq7t82sOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import FreqDist\n",
        "\n",
        "freq_book1 = FreqDist(book1_clean)\n",
        "freq_book2 = FreqDist(book2_clean)\n",
        "\n",
        "print(\"Top 10 Most Common Words in 'Emma':\")\n",
        "print(freq_book1.most_common(10))\n",
        "\n",
        "print(\"\\nTop 10 Most Common Words in 'Bible':\")\n",
        "print(freq_book2.most_common(10))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 Most Common Words in 'Emma':\n",
            "[('mr', 1153), ('emma', 865), ('could', 837), ('would', 820), ('mrs', 699), ('miss', 599), ('must', 567), ('harriet', 506), ('much', 486), ('said', 484)]\n",
            "\n",
            "Top 10 Most Common Words in 'Bible':\n",
            "[('shall', 9838), ('unto', 8997), ('lord', 7964), ('thou', 5474), ('thy', 4600), ('god', 4472), ('said', 3999), ('ye', 3983), ('thee', 3827), ('upon', 2748)]\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "_pJDrSzR201V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a11388f-26f1-407a-975a-044bee09a0d5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 4.2 Bigram Analysis\n"
      ],
      "metadata": {
        "id": "Yk68xPD320LV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import bigrams\n",
        "\n",
        "bigrams_book1 = list(bigrams(book1_clean))\n",
        "bigrams_book2 = list(bigrams(book2_clean))\n",
        "\n",
        "freq_bigrams_book1 = FreqDist(bigrams_book1)\n",
        "freq_bigrams_book2 = FreqDist(bigrams_book2)\n",
        "\n",
        "print(\"Top 10 Bigrams in 'Emma':\")\n",
        "print(freq_bigrams_book1.most_common(10))\n",
        "\n",
        "print(\"\\nTop 10 Bigrams in 'Bible':\")\n",
        "print(freq_bigrams_book2.most_common(10))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 Bigrams in 'Emma':\n",
            "[(('mr', 'knightley'), 299), (('mrs', 'weston'), 256), (('mr', 'elton'), 229), (('miss', 'woodhouse'), 173), (('mr', 'weston'), 167), (('frank', 'churchill'), 151), (('mrs', 'elton'), 150), (('mr', 'woodhouse'), 135), (('every', 'thing'), 126), (('miss', 'fairfax'), 125)]\n",
            "\n",
            "Top 10 Bigrams in 'Bible':\n",
            "[(('said', 'unto'), 1697), (('thou', 'shalt'), 1250), (('lord', 'god'), 960), (('saith', 'lord'), 859), (('thou', 'hast'), 773), (('ye', 'shall'), 770), (('children', 'israel'), 648), (('unto', 'lord'), 629), (('unto', 'thee'), 504), (('came', 'pass'), 458)]\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "ViGcXMRx22Md",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "956dd6ab-12d8-4b91-e053-01610a664372"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Which high-frequency words are function words and which are lexical words?\n",
        "\n",
        "2. How does removing function words help highlight the lexical words that convey the main themes or ideas in each text?"
      ],
      "metadata": {
        "id": "RMNyAOmA28eF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 1:\n",
        "\n",
        "Function words (also called stop words) are words that primarily serve grammatical purposes, such as prepositions (e.g., \"of,\" \"in,\" \"on\"), conjunctions (e.g., \"and,\" \"but,\" \"or\"), articles (e.g., \"a,\" \"an,\" \"the\"), and pronouns (e.g., \"he,\" \"she,\" \"it\").\n",
        "\n",
        "Lexical words (also called content words) are words that carry the main meaning of a sentence, such as nouns (e.g., \"cat,\" \"house,\" \"idea\"), verbs (e.g., \"run,\" \"eat,\" \"think\"), adjectives (e.g., \"happy,\" \"big,\" \"red\"), and adverbs (e.g., \"quickly,\" \"loudly,\" \"happily\").\n",
        "\n",
        "Looking at the top 10 most frequent words in 'Emma' and 'Bible' from the code output:\n",
        "\n",
        "'Emma':\n",
        "\n",
        "Lexical words: emma, could, would, said, miss, must, think, much, every, one.\n",
        "Some words in the list (could, would, must) might be considered function words depending on context, but in this literary context, they more often express character thoughts and feelings.\n",
        "'Bible':\n",
        "\n",
        "Lexical words: god, lord, shall, unto, thy, said, thee, man, people, came.\n",
        "Function words: unto, thy, thee"
      ],
      "metadata": {
        "id": "q5N-_116iqTf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 2:\n",
        "\n",
        "Removing function words helps highlight lexical words and themes in several ways:\n",
        "\n",
        "Reduced Noise: Function words are very common but often don't contribute much to the core meaning. By removing them, we reduce noise and focus on the important words.\n",
        "Emphasis on Content: When function words are removed, the remaining lexical words become more prominent, emphasizing the key concepts and ideas in the text.\n",
        "Improved Analysis: This makes it easier to analyze the text's main themes, topics, and the author's style. For example, in 'Emma', focusing on words like \"emma,\" \"miss,\" \"think,\" and \"much\" could reveal insights into character relationships and social dynamics. In 'Bible', words like \"god,\" \"lord,\" and \"shall\" reflect religious themes and commandments."
      ],
      "metadata": {
        "id": "8Tmrr4kTix_p"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python",
      "language": "python",
      "display_name": "Pyolite (preview)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernel_info": {
      "name": "python"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}